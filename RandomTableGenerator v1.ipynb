{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bba84f-c5b1-46b7-977c-c72a2535ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyparsing as pp\n",
    "from pyparsing import pyparsing_common as ppc\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7535d3a-beee-408c-84bb-61f2927ff98f",
   "metadata": {},
   "source": [
    "5 edgerunners are on top of arasaka tower. They are bleeding out having been shot by arasaka security forces. Arasaka security forces are still there. Only 1 of them has TT membership. Oh and there is a blidning thunderstorm with rain obscuring visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031ad74-a589-4fcf-aa65-b58a91e99f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{number}{who}{where}. {injury} having been {danger}. {Danger} is/are still present. {x} of them has/have TT membership. Oh and {modifier}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d55825-3d28-48a3-a84a-295a7db643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# must combine person and number. they should always come together. whenver person is pulled the number should always be calculated with it.\n",
    "who = 'Edgerunner(s)'\n",
    "number = np.round(np.exp(np.abs(np.random.randn())))\n",
    "\n",
    "injury = \"lost limbs\"\n",
    "injury_urgency = 'high'\n",
    "location = 'Arasaka tower'\n",
    "\n",
    "# write a function that creates a chance of having several injuries\n",
    "threat = 'Arasaka strike team'\n",
    "threat_present = True\n",
    "tt_memberships = min(np.random.geometric(p=0.9),number)\n",
    "tt_cover_type = 'Silver'\n",
    "\n",
    "modifier = 'severe thunderstorm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f75c57-557a-41c5-945d-75a227223f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "f\"\"\"Who?\\t\\t{who}\n",
    "How many?\\t{number:n}\n",
    "TT memberships\\t{tt_memberships:n}\n",
    "Injury\\t\\t{injury}\n",
    "Injury urgency\\t{injury_urgency}\n",
    "Where?\\t\\t{location}\n",
    "Threat\\t\\t{threat}\n",
    "Threat present?\\t{'Yes' if threat_present else 'No'}\n",
    "Modifier\\t{modifier}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3719102-c3f4-4ec6-b547-c466084a0bef",
   "metadata": {},
   "source": [
    "- If the top row of the random table input does not have any generators then it is used as a title of the table\n",
    "- if any subsequent row does not have any generators the text is just output as is.\n",
    "- look into inputting file when running python from terminal\n",
    "- ~~define vlo/lo/med/hi/vhi distributions~~\n",
    "- in the class have default values for the distributions but allow for people to input their own upon init\n",
    "\n",
    "\n",
    "- make process input file a method that has to be called separately and not upon __init__\n",
    "- after that retry the dictionary method of process input line\n",
    "- add an error handling for no table found - try, else, finally\n",
    "- create a tool that inspects all the lines in all the tables and surfaces the lines that have errors in them.\n",
    "\n",
    "- add more ways to do number generation. it shouldn't be just the geometric distributino.\n",
    "    - add uniform 0-9 so that any number can be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "4162104b-32d3-4ec5-a599-3f9a7fa8d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control line Camels space\n",
      "test1 fail\n",
      "test2 friends forever or \n",
      "test3 hola beef without we are victorious soup\n",
      "test4 second bracket outside the brackets\n",
      " Trauma Team 2\n"
     ]
    }
   ],
   "source": [
    "class Random_Table_Generator:\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        distribution_modifier=1,\n",
    "        tables_folder = 'tables',\n",
    "        input_phrase = None,\n",
    "        default_chance_increase = 2,\n",
    "        default_chance_decrease = 0.5,\n",
    "        default_option = 0.5,\n",
    "        default_boolean = 0.5,\n",
    "        loop_limit = 100,\n",
    "        dist_dict = {\n",
    "            'vlo': 0.9,\n",
    "            'lo':  0.7,\n",
    "            'med': 0.3,\n",
    "            'hi':  0.2,\n",
    "            'vhi': 0.1\n",
    "        }\n",
    "    ):\n",
    "        self.distribution = distribution_modifier\n",
    "        self.default_chance_increase = default_chance_increase\n",
    "        self.default_chance_decrease = default_chance_decrease\n",
    "        self.default_option = default_option\n",
    "        self.default_boolean = default_boolean\n",
    "        self.tables_folder = tables_folder\n",
    "        self.input_phrase = input_phrase\n",
    "        self.loop_limit = loop_limit\n",
    "        self.dist_dict = dist_dict\n",
    "        \n",
    "        # defining patterns for pyparsing\n",
    "        self.option_pat_combo    = '%' + pp.Opt(ppc.fnumber()) + pp.nested_expr(opener='[', closer=']')\n",
    "        self.option_pat_combo2   = pp.original_text_for('%' + pp.Opt(ppc.fnumber()('chance')) + '.' + pp.original_text_for(pp.nested_expr(opener='[', closer=']'))('heads') + pp.Opt('.') + pp.original_text_for(pp.Opt((pp.nested_expr(opener='[', closer=']'))))('tails'))\n",
    "        self.option_pat_indiv_orig    = '%' + pp.Opt(ppc.fnumber()('chance')) + '.' + pp.original_text_for(pp.nested_expr(opener='[', closer=']'))('heads') + pp.Opt('.') + pp.original_text_for(pp.Opt(pp.nested_expr(opener='[', closer=']')))('tails')\n",
    "        self.option_pat_indiv    = '%' + pp.Opt(ppc.fnumber()('chance')) + '.' + pp.original_text_for(pp.nested_expr(opener='[', closer=']'))('heads') + pp.Opt('.') + pp.original_text_for(pp.Opt(pp.nested_expr(opener='[', closer=']')))('tails') \n",
    "        self.table_pat           = pp.Combine('@' + pp.Word(pp.printables, exclude_chars=']'))\n",
    "        self.number_pat_combo    = pp.Combine('#' + pp.Word(pp.printables))\n",
    "        self.number_pat_indiv    = '#' + pp.Word(pp.alphas)('dist') + pp.Opt('.') + pp.Opt(pp.Word(pp.nums)('max'))\n",
    "        self.boolean_pat_combo   = pp.Combine('$' + pp.Opt(ppc.fnumber) + \".\" + pp.Word(pp.alphanums) + \".\" + pp.Word(pp.alphanums))\n",
    "        self.boolean_pat_indiv   = '$' + pp.Opt(ppc.fnumber)('chance') + \".\" + pp.Word(pp.alphanums)('heads') + \".\" + pp.Word(pp.alphanums)('tails')\n",
    "        self.chance_increase_pat = pp.Combine(pp.StringStart() + '^' + pp.Opt(ppc.fnumber()))\n",
    "        self.chance_decrease_pat = pp.Combine(pp.StringStart() + '*' + pp.Opt(ppc.fnumber()))\n",
    "        self.pat_dict = {\n",
    "            'process_table': self.table_pat\n",
    "            ,'process_boolean': self.boolean_pat_combo\n",
    "            ,'process_number': self.number_pat_combo\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "    def process_input_file(self, input_file):\n",
    "        file = open(input_file, 'r').read().split('\\n')\n",
    "        for line in file:\n",
    "            processed_line = self.process_input_line(line)\n",
    "            print(processed_line)\n",
    "            \n",
    "            \n",
    "    def process_input_phrase(self, input_phrase):\n",
    "        # is this the same as process_input_line?\n",
    "        pass\n",
    "    \n",
    "    def test_process_input_line(self, line):\n",
    "        # this is for testing the compact dictionary version of process_input_line.\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def process_input_line(self, line):\n",
    "        # the expanded version that works without the pat_dict\n",
    "        \n",
    "        gen_check = False\n",
    "        outputs = []\n",
    "        matches_option_pat = Random_Table_Generator.option_pat_combo2.scan_string(line)\n",
    "        for match, start, stop in matches_option_pat:\n",
    "            gen_check = True\n",
    "            output = self.process_input_line(self.process_option(match))\n",
    "            outputs.append((match, output, start, stop))\n",
    "        if gen_check:\n",
    "            line = self.replace(line, outputs)\n",
    "        \n",
    "        gen_check = False\n",
    "        outputs = []\n",
    "        matches_table_pat = Random_Table_Generator.table_pat.scan_string(line)\n",
    "        for match, start, stop in matches_table_pat:\n",
    "            gen_check = True\n",
    "            output = self.process_input_line(self.process_table(match))\n",
    "            outputs.append((match, output, start, stop))\n",
    "        if gen_check:\n",
    "            line = self.replace(line, outputs)\n",
    "        \n",
    "        gen_check = False\n",
    "        outputs = []\n",
    "        matches_number_pat = Random_Table_Generator.number_pat_combo.scan_string(line)\n",
    "        for match, start, stop in matches_number_pat:\n",
    "            gen_check = True\n",
    "            output = self.process_input_line(self.process_number(match))\n",
    "            outputs.append((match, output, start, stop))\n",
    "        if gen_check:\n",
    "            line = self.replace(line, outputs)\n",
    "        \n",
    "        gen_check = False\n",
    "        outputs = []\n",
    "        matches_boolean_pat = Random_Table_Generator.boolean_pat_combo.scan_string(line)\n",
    "        for match, start, stop in matches_boolean_pat:\n",
    "            gen_check = True\n",
    "            output = self.process_input_line(self.process_boolean(match))\n",
    "            outputs.append((match, output, start, stop))\n",
    "        if gen_check:\n",
    "            line = self.replace(line, outputs)\n",
    "        \n",
    "        return line\n",
    "\n",
    "    \n",
    "    def replace(self, line, mappings):\n",
    "        slices, indices, output = [], [0], []\n",
    "        for mapping,_, start, end in mappings:\n",
    "            if str(mapping[0])[-1] == ' ':\n",
    "                end -= 1\n",
    "            indices += [start,end]\n",
    "\n",
    "        # if len(line) != mappings[-1][-1]:\n",
    "        #     indices += [None]\n",
    "        indices += [None]\n",
    "\n",
    "        for i in range(0,len(indices),2):\n",
    "            slices.append(slice(indices[i], indices[i+1]))\n",
    "\n",
    "        if mappings[0][2] == 0:\n",
    "            for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "                output += [new_word, line[i]]\n",
    "            if len(mappings) > len(slices):\n",
    "                output += [mappings[-1][1]] \n",
    "        else:\n",
    "            for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "                output += [line[i], new_word]\n",
    "            if len(mappings) < len(slices):\n",
    "                output += [line[slices[-1]]] \n",
    "        return ''.join(output)\n",
    "\n",
    "    \n",
    "    def process_option(self, instruction):\n",
    "        for match, start, stop in Random_Table_Generator.option_pat_indiv.scan_string(instruction):\n",
    "            if match.chance == '':\n",
    "                probability = default_boolean\n",
    "            else:\n",
    "                probability = match.chance\n",
    "            random_value = np.random.random()\n",
    "            \n",
    "            return (match.heads[1:-1] if random_value <= probability else match.tails[1:-1])\n",
    "    \n",
    "    \n",
    "    def process_table(self, reference):\n",
    "        input_file = self.tables_folder + '/' + reference[0][1:] + '.txt'\n",
    "        file = open(input_file, 'r').read().split('\\n')\n",
    "\n",
    "        probabilities = np.ones(len(file))\n",
    "\n",
    "        for line_no, line in enumerate(file):\n",
    "            matches_increase = Random_Table_Generator.chance_increase_pat.scan_string(line)\n",
    "            for match, start, end in matches_increase:\n",
    "                if end == 1:\n",
    "                    probabilities[line_no] = self.default_chance_increase\n",
    "                else:\n",
    "                    probabilities[line_no] = float(match[0][1:])\n",
    "                file[line_no] = line[(end+1):]\n",
    "\n",
    "            matches_decrease = Random_Table_Generator.chance_decrease_pat.scan_string(line)\n",
    "            for match, start, end in matches_decrease:\n",
    "                if end == 1:\n",
    "                    probabilities[line_no] = self.default_chance_decrease\n",
    "                else:\n",
    "                    probabilities[line_no] = float(match[0][1:])\n",
    "                file[line_no] = line[(end+1):]\n",
    "\n",
    "        probabilities_cum = np.cumsum(probabilities)\n",
    "        random_value = np.random.uniform(0,probabilities.sum(),1)\n",
    "        pick = np.argmax((probabilities_cum // random_value)>0)\n",
    "        \n",
    "        return file[pick]\n",
    "    \n",
    "    \n",
    "    def process_number(self, instruction):\n",
    "        for match, start, end in Random_Table_Generator.number_pat_indiv.scan_string(instruction):\n",
    "            random_value = np.random.geometric(p=self.dist_dict[match.dist])\n",
    "            if match.max == '':\n",
    "                return random_value\n",
    "            else:\n",
    "                return (str(random_value) if int(match.max) > random_value else match.max)\n",
    "    \n",
    "    \n",
    "    def process_boolean(self, instruction):\n",
    "        for match, start, end in Random_Table_Generator.boolean_pat_indiv.scan_string(instruction):\n",
    "            if match.chance == '':\n",
    "                probability = self.default_boolean\n",
    "            else:\n",
    "                probability = match.chance\n",
    "            random_value = np.random.random()\n",
    "            return (match.heads if random_value <= probability else match.tails)\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "rtg = Random_Table_Generator()\n",
    "rtg.process_input_file(\"TEST.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb320ba-690b-416a-816b-d411f04c6e8d",
   "metadata": {},
   "source": [
    "### Process Option Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eacd5-3a40-4238-8247-71932498cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('TEST.txt', 'r').read().split('\\n')\n",
    "\n",
    "option_pat = '%' + pp.Opt(ppc.fnumber()) + pp.nested_expr(opener='[', closer=']')\n",
    "table_pat = '@' + pp.Word(pp.printables)\n",
    "\n",
    "pat_dict = {\n",
    "    'option_pat': option_pat,\n",
    "    'table_pat': table_pat\n",
    "}\n",
    "\n",
    "del matches\n",
    "\n",
    "def table_pat():\n",
    "    print('test successful!')\n",
    "\n",
    "for i in pat_dict:\n",
    "    locals()[i]()\n",
    "    for line in file:\n",
    "        print('\\n\\n'+ line)\n",
    "        matches = pat_dict[i].scanString(line)\n",
    "\n",
    "        for match, start, stop in matches:\n",
    "            print(match, start, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cbfd09b7-92b8-410d-b450-5e7e9dacdd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['@animal'] 13 20\n",
      "<class 'str'>\n",
      "['@animal'] 49 56\n"
     ]
    }
   ],
   "source": [
    "file = open('TEST.txt', 'r').read().split('\\n')\n",
    "table_pat = pp.Combine('@' + pp.Word(pp.printables, exclude_chars=']'))\n",
    "\n",
    "\n",
    "for line in file:\n",
    "    matches = table_pat.scan_string(line)\n",
    "    for a,b,c in matches:\n",
    "        print(type(str(a)))\n",
    "        print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7568aca3-4a3a-41df-a610-bf1d06cff278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full match for this line is:  ['%', '.', '[success]', '.', '[fail]'] 6 24\n",
      "chance for this line is:  \n",
      "heads for this line is:  [success]\n",
      "tails for this line is:  ['[fail]']\n",
      "random_value=0.06223249279666143\n",
      "result for test_option1 is:  success \n",
      "\n",
      "full match for this line is:  ['%', 0.9, '.', '[friends forever]'] 6 29\n",
      "chance for this line is:  0.9\n",
      "heads for this line is:  [friends forever]\n",
      "tails for this line is:  \n",
      "random_value=0.24710868022238064\n",
      "result for test_option2 is:  friends forever \n",
      "\n",
      "full match for this line is:  ['%', '.', '[hola %0.9.[beef without %.[we are victorious] soup]]'] 6 61\n",
      "chance for this line is:  \n",
      "heads for this line is:  [hola %0.9.[beef without %.[we are victorious] soup]]\n",
      "tails for this line is:  \n",
      "random_value=0.05926164424516245\n",
      "result for test_option3 is:  hola %0.9.[beef without %.[we are victorious] soup] \n",
      "\n",
      "full match for this line is:  ['%', '.', '[success]', '.'] 6 20\n",
      "chance for this line is:  \n",
      "heads for this line is:  [success]\n",
      "tails for this line is:  \n",
      "random_value=0.18521230912474618\n",
      "result for test_option4 is:  success \n",
      "\n"
     ]
    }
   ],
   "source": [
    "option_pat_combo = '%' + pp.Combine(pp.Opt(ppc.fnumber()) + '.' + pp.nested_expr(opener='[', closer=']') + pp.Opt('.') + pp.Opt(pp.nested_expr(opener='[', closer=']')))\n",
    "option_pat_combo2 = pp.original_text_for('%' + pp.Opt(ppc.fnumber()('chance')) + '.' + pp.original_text_for(pp.nested_expr(opener='[', closer=']'))('heads') + pp.Opt('.') + pp.Opt(pp.original_text_for(pp.nested_expr(opener='[', closer=']')))('tails'))\n",
    "option_pat_indiv = '%' + pp.Opt(ppc.fnumber()('chance')) + '.' + pp.original_text_for(pp.nested_expr(opener='[', closer=']'))('heads') + pp.Opt('.') + pp.Opt(pp.original_text_for(pp.nested_expr(opener='[', closer=']')))('tails')\n",
    "\n",
    "default_boolean = 0.5\n",
    "\n",
    "\n",
    "def process_option(line):\n",
    "    for match, start, stop in option_pat_indiv.scan_string(line):\n",
    "        print('full match for this line is: ', match, start, stop)\n",
    "        print('chance for this line is: ', match.chance)\n",
    "        print('heads for this line is: ', match.heads)\n",
    "        print('tails for this line is: ', match.tails)\n",
    "\n",
    "        if match.chance == '':\n",
    "            probability = default_boolean\n",
    "        else:\n",
    "            probability = match.chance\n",
    "        random_value = np.random.random()\n",
    "        print(f'{random_value=}')\n",
    "        \n",
    "        return (match.heads[1:-1] if random_value <= probability else match.tails[0][1:-1])\n",
    "\n",
    "    \n",
    "test_option1 = \"test1 %.[success].[fail]\"\n",
    "test_option2 = \"test2 %0.9.[friends forever] or %.[never will be @friends]\"\n",
    "test_option3 = \"test3 %.[hola %0.9.[beef without %.[we are victorious] soup]]\"\n",
    "test_option4 = \"test4 %.[success] . and then it goes on\"\n",
    "\n",
    "print(f'result for test_option1 is: ', process_option(test_option1), '\\n')\n",
    "print(f'result for test_option2 is: ', process_option(test_option2), '\\n')\n",
    "print(f'result for test_option3 is: ', process_option(test_option3), '\\n')\n",
    "print(f'result for test_option4 is: ', process_option(test_option4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0f746-8a97-455b-8b58-6e86bc9a8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_test = pp.nested_expr(opener='[', closer=']')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438ca60-53b6-4073-8e75-4e22e968f2bc",
   "metadata": {},
   "source": [
    "### Replace Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48ad65-2c66-4a7f-9384-667c72da8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_line = 'as we are going to the supermarket to buy apples'\n",
    "mappings = [('we', 'they', 3, 5), ('supermarket', 'bazaar', 23, 34)]\n",
    "\n",
    "slices = []\n",
    "indices = [0]\n",
    "output = []\n",
    "\n",
    "for _,_, start, end in mappings:\n",
    "    indices += [start,end]\n",
    "\n",
    "if len(test_line) != mappings[-1][-1]:\n",
    "    indices += [-1]\n",
    "\n",
    "print(indices)\n",
    "\n",
    "for i in range(0,len(indices),2):\n",
    "    print(i)\n",
    "    slices.append(slice(indices[i], indices[i+1]))\n",
    "\n",
    "print(slices)\n",
    "    \n",
    "if mappings[0][2] == 0:\n",
    "    for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "        output += [new_word, test_line[i]]\n",
    "    if len(mappings) > len(slices):\n",
    "        output += [mappings[-1][1]] \n",
    "\n",
    "else:\n",
    "    for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "        output += [test_line[i], new_word]\n",
    "    if len(mappings) < len(slices):\n",
    "        output += [test_line[slices[-1]]] \n",
    "\n",
    "    \n",
    "    \n",
    "def replace(line, mappings):\n",
    "    slices, indices, output = [], [0], []\n",
    "\n",
    "    for _,_, start, end in mappings:\n",
    "        indices += [start,end]\n",
    "\n",
    "    if len(line) != mappings[-1][-1]:\n",
    "        indices += [None]\n",
    "\n",
    "    for i in range(0,len(indices),2):\n",
    "        slices.append(slice(indices[i], indices[i+1]))\n",
    "\n",
    "    if mappings[0][2] == 0:\n",
    "        for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "            output += [new_word, line[i]]\n",
    "        if len(mappings) > len(slices):\n",
    "            output += [mappings[-1][1]] \n",
    "    else:\n",
    "        for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "            output += [line[i], new_word]\n",
    "        if len(mappings) < len(slices):\n",
    "            output += [line[slices[-1]]] \n",
    "\n",
    "\n",
    "    return ''.join(output)\n",
    "\n",
    "replace(test_line, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405c32a-da1c-47ee-a2df-2e98b23203d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(line, mappings):\n",
    "    slices = []\n",
    "    indices = [0]\n",
    "    output = []\n",
    "\n",
    "    for _,_, start, end in mappings:\n",
    "        indices += [start,end]\n",
    "\n",
    "    if len(line) != mappings[-1][-1]:\n",
    "        indices += [None]\n",
    "\n",
    "    for i in range(0,len(indices),2):\n",
    "        slices.append(slice(indices[i], indices[i+1]))\n",
    "\n",
    "    if mappings[0][2] == 0:\n",
    "        for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "            output += [new_word, line[i]]\n",
    "        if len(mappings) > len(slices):\n",
    "            output += [mappings[-1][1]] \n",
    "    else:\n",
    "        for new_word, i in zip([i[1] for i in mappings], slices):\n",
    "            output += [line[i], new_word]\n",
    "        if len(mappings) < len(slices):\n",
    "            output += [line[slices[-1]]] \n",
    "\n",
    "\n",
    "    return ''.join(output)\n",
    "\n",
    "replace(test_line, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58477d-aabd-4310-9845-c81f801a44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW SNIP NEW SNIP NEW\n",
    "NEW SNIP NEW SNIP\n",
    "\n",
    "SNIP NEW SNIP NEW SNIP\n",
    "SNIP NEW SNIP NEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f998d-a568-49ae-bb8d-ea9980bc0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[1] for i in mappings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888a564-6a56-412e-ac32-59d986bab01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = slice(0,3)\n",
    "b = slice(5,23)\n",
    "c = slice(34,-1)\n",
    "test_list = [test_line[a], test_line[b], test_line[c]]\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c9927-75ac-4919-9961-9d42fe6a620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_line[:None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448412c-13b1-4941-92e3-9b8096c51412",
   "metadata": {},
   "source": [
    "### Process Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afc55c-44f6-4390-b014-104d8379eb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chance_increase_pat = pp.Combine(pp.StringStart() + '^' + pp.Opt(ppc.fnumber()))\n",
    "chance_decrease_pat = pp.Combine(pp.StringStart() + '*' + pp.Opt(ppc.fnumber()))\n",
    "\n",
    "default_chance_increase = 2\n",
    "default_chance_decrease = 0.5\n",
    "\n",
    "def process_table(reference):\n",
    "    input_folder = 'tables'\n",
    "    input_file = input_folder + '/' + reference[1:] + '.txt'\n",
    "    file = open(input_file, 'r').read().split('\\n')\n",
    "    \n",
    "    probabilities = np.ones(len(file))\n",
    "\n",
    "    for line_no, line in enumerate(file):\n",
    "        matches_increase = chance_increase_pat.scan_string(line)\n",
    "        for match, start, end in matches_increase:\n",
    "            if end == 1:\n",
    "                probabilities[line_no] = default_chance_increase\n",
    "            else:\n",
    "                probabilities[line_no] = float(match[0][1:])\n",
    "            file[line_no] = line[(end+1):]\n",
    "        \n",
    "        matches_decrease = chance_decrease_pat.scan_string(line)\n",
    "        for match, start, end in matches_decrease:\n",
    "            if end == 1:\n",
    "                probabilities[line_no] = default_chance_decrease\n",
    "            else:\n",
    "                probabilities[line_no] = float(match[0][1:])\n",
    "            file[line_no] = line[(end+1):]\n",
    "    \n",
    "\n",
    "    probabilities_cum = np.cumsum(probabilities)\n",
    "    random_value = np.random.uniform(0,probabilities.sum(),1)\n",
    "    pick = np.argmax((probabilities_cum // random_value)>0)\n",
    "    \n",
    "    return file[pick]\n",
    "    \n",
    "    \n",
    "test_reference = '@corporation'\n",
    "process_table(test_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a18d6e-e504-4907-95f9-915320b7e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in tqdm(range(10000)):\n",
    "    result.append(process_table(test_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab4fbf-9a26-4312-be51-3ba198eac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(data=result)\n",
    "ax.set_xticklabels(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06203e-14fe-4b8c-9037-b05f9697a1b4",
   "metadata": {},
   "source": [
    "### Process Boolean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185958d-e802-41b3-a365-7fb18bc0d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_pat_combo = pp.Combine('$' + pp.Opt(ppc.fnumber) + \".\" + pp.Word(pp.alphanums) + \".\" + pp.Word(pp.alphanums))\n",
    "boolean_pat_indiv = '$' + pp.Opt(ppc.fnumber)('chance') + \".\" + pp.Word(pp.alphanums)('heads') + \".\" + pp.Word(pp.alphanums)('tails')\n",
    "default_boolean = 0.5\n",
    "\n",
    "def process_boolean(instruction):\n",
    "    for match, start, end in boolean_pat_indiv.scan_string(instruction):\n",
    "        if match.chance == '':\n",
    "            probability = default_boolean\n",
    "        else:\n",
    "            probability = match.chance\n",
    "        random_value = np.random.random()\n",
    "        return (match.heads if random_value <= probability else match.tails)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_instruction1 = '$.Yes.No'\n",
    "test_instruction2 = '$0.8.Success.Fail'\n",
    "\n",
    "print(process_boolean(test_instruction1))\n",
    "print(process_boolean(test_instruction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853742e-f771-4b30-b5d1-252c4c9f67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7c24c-9878-46c4-a9d1-01ad5103cec7",
   "metadata": {},
   "source": [
    "### Process Number Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc4fcb-8c50-4bf9-8ccc-1d0b9f0349bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pat_indiv    = '#' + pp.Word(pp.alphas)('dist') + pp.Opt('.') + pp.Opt(pp.Word(pp.nums)('max'))\n",
    "\n",
    "dist_dict = {\n",
    "    'vlo': 0.9,\n",
    "    'lo':  0.7,\n",
    "    'med': 0.3,\n",
    "    'hi':  0.2,\n",
    "    'vhi': 0.1\n",
    "}\n",
    "\n",
    "def process_number(instruction):\n",
    "    for match, start, end in number_pat_indiv.scan_string(instruction):\n",
    "        random_value = np.random.geometric(p=dist_dict[match.dist])\n",
    "        if match.max == '':\n",
    "            return random_value\n",
    "        else:\n",
    "            return (str(random_value) if int(match.max) > random_value else match.max)\n",
    "\n",
    "\n",
    "test_instruction1 = '#vlo'\n",
    "test_instruction2 = '#hi.5'\n",
    "\n",
    "print(process_number(test_instruction1))\n",
    "print(process_number(test_instruction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86118f-c4e0-4bc9-9310-cbc850677106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
